{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = pd.read_csv('data/account.csv', encoding='ISO-8859-1')\n",
    "concerts_1415=pd.read_csv('data/concerts_2014-15.csv')\n",
    "concerts=pd.read_csv('data/concerts.csv')\n",
    "sample_submission=pd.read_csv('data/sample_submission.csv')\n",
    "subscriptions=pd.read_csv('data/subscriptions.csv')\n",
    "test=pd.read_csv('data/test.csv')\n",
    "tickets_all=pd.read_csv('data/tickets_all.csv')\n",
    "train=pd.read_csv('data/train.csv')\n",
    "zipcodes=pd.read_csv('data/zipcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Subscription and Construct Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## The player in season 2014-2015 \n",
    "player_1415=['Nicholas McGegan','Steven Isserlis','Julian Wachner','Andreas Scholl','Dominique Labelle','Christopher Ainslie','Thomas Cooley','Dashon Burton',\\\n",
    "             'Bruce Lamott','Sherezade Panthaki','Clifton Massey','Brian Thorsett','Jeffrey Fields',\\\n",
    "                'Rachel Podger',' Ted Huffman']\n",
    "\n",
    "key_content_1415 = ['LÕestro armonico','VIVALDI','HAYDN','HANDEL','BACH','CANTATA','TELEMANN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle subscription data\n",
    "def handle_subscription(group):\n",
    "    # Safely handle NaN values in cities\n",
    "    shipping_city = group['shipping.city'].fillna(\"\")\n",
    "    billing_city = group['billing.city'].fillna(\"\")\n",
    "\n",
    "    # If there are any subscription data\n",
    "    if group['season'].notna().any():\n",
    "\n",
    "        has_previous_player = False\n",
    "        has_previous_key_content = False\n",
    "\n",
    "        previous_player_subscription_number = 0\n",
    "        previous_key_content_subscription_number = 0\n",
    "    \n",
    "        for season, location in zip(group['season'],group['location']):\n",
    "\n",
    "            result = concerts.query('season == @season and location == @location')\n",
    "\n",
    "            player_content = result['who']\n",
    "\n",
    "            key_content = result['what']\n",
    "            \n",
    "            # Join list items into a single regex pattern\n",
    "            pattern_player = \"|\".join(map(re.escape, player_1415))\n",
    "            pattern_content = \"|\".join(map(re.escape, key_content_1415))\n",
    "\n",
    "            # Check if any word is in the string\n",
    "            has_previous_player = player_content.str.contains(pattern_player,regex=True).any()\n",
    "            has_previous_key_content = key_content.str.contains(pattern_content,regex=True).any()\n",
    "\n",
    "            if has_previous_player :\n",
    "                previous_player_subscription_number += 1\n",
    "            \n",
    "            if has_previous_key_content:\n",
    "                previous_key_content_subscription_number += 1\n",
    "            \n",
    "        return pd.DataFrame({\n",
    "\n",
    "            # Total season:\n",
    "            'total_season': [group.shape[0]],\n",
    "\n",
    "            # Package features\n",
    "            'full_package': [(group['package'] == 'Full').sum()],\n",
    "            'quartet_package': [(group['package'].isin(['Quartet', 'Quartet A', 'Quartet B', 'Quartet CC'])).sum()],\n",
    "            'trio_package': [(group['package'].isin(['Trio', 'Trio A', 'Trio B'])).sum()],\n",
    "            'cyo_package': [(group['package'] == 'CYO').sum()],\n",
    "            'full_upgrade_package': [(group['package'] == 'Full upgrade').sum()],\n",
    "\n",
    "            # Seat features\n",
    "            'total_seats_sub': [group['no.seats'].sum()],\n",
    "\n",
    "            # Location features\n",
    "            'location_num_sub': [group['location'].nunique()],\n",
    "            # 'location_near_resident_num_sub': [(group['location'] == shipping_city).sum() if shipping_city.any() else (group['location'] == billing_city).sum()],\n",
    "            # 'location_not_resident_num_sub': [group.shape[0] - (group['location'] == shipping_city).sum() if shipping_city.any() else group.shape[0] - (group['location'] == billing_city).sum()],\n",
    "\n",
    "            # Section features\n",
    "            'section_type_numbers': [group['section'].nunique()],\n",
    "            'premium_orchestra_number': [(group['section'] == 'Premium Orchestra').sum()],\n",
    "            'orchestra_number': [(group['section'].isin(['Orchestra', 'Orchestra Front', 'Orchestra Rear'])).sum()],\n",
    "            'balcony_number': [(group['section'].isin(['Balcony Front', 'Balcony Rear', 'Balcony', 'Santa Rosa'])).sum()],\n",
    "            'dress_circle_number': [(group['section'] == 'Dress Circle').sum()],\n",
    "            'Gallery_number': [(group['section'] == 'Gallery').sum()],\n",
    "            'Box_number': [(group['section'].isin(['Box', 'Box House Left', 'Box House Right'])).sum()],\n",
    "            'floor_number': [(group['section'] == 'Floor').sum()],\n",
    "\n",
    "            # Price features (some seasons do not have price level data using another feature to present it and calculate mean without them)\n",
    "            'mean_price_level': [-1 if (~group['price.level'].isna()).sum()==0 else group[~group['price.level'].isna()]['price.level'].mean()],\n",
    "\n",
    "            'non_price_level_subscription': [group['season'].isin(['2002-2003','2003-2004','2004-2005']).sum()],\n",
    "\n",
    "            # Subscription tier features\n",
    "            'mean_subscription_tier': [group['subscription_tier'].mean()],\n",
    "            'multiple_subs_number': [(group['multiple.subs'] == 'yes').sum()],\n",
    "            \n",
    "            # # Whether the 1415_concerts contain the same player for their previous tickets\n",
    "            # 'has_previous_player': [has_previous_player],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same key_content for their previous tickets\n",
    "            # 'has_previous_key_content': [has_previous_key_content],\n",
    "            \n",
    "            # previous player and key_content subscription number\n",
    "            'previous_player_subscription_number': [previous_player_subscription_number],\n",
    "\n",
    "            'previous_key_content_subscription_number': [previous_key_content_subscription_number], \n",
    "\n",
    "            # other features\n",
    "            'account.id': [group['account.id'].iloc[0]],\n",
    "            'label': [group['label'].iloc[0]] if 'label' in group.columns else [-1],\n",
    "            'shipping.zip.code': [group['shipping.zip.code'].iloc[0]],\n",
    "            'billing.zip.code': [group['billing.zip.code'].iloc[0]],\n",
    "            'shipping_city': [shipping_city.iloc[0]],\n",
    "            'billing_city': [billing_city.iloc[0]],\n",
    "            'relationship': [group['relationship'].iloc[0]],\n",
    "            'amount.donated.2013': [group['amount.donated.2013'].iloc[0]],\n",
    "            'amount.donated.lifetime': [group['amount.donated.lifetime'].iloc[0]],\n",
    "            'no.donations.lifetime': [group['no.donations.lifetime'].iloc[0]],\n",
    "            'first.donated': [group['first.donated'].iloc[0]],\n",
    "        })\n",
    "    \n",
    "    # no subscription data, just fill with -1\n",
    "    else:\n",
    "        return pd.DataFrame({\n",
    "            # Total season:\n",
    "            'total_season': [0],\n",
    "\n",
    "            # Package features\n",
    "            'full_package': [0],\n",
    "            'quartet_package': [0],\n",
    "            'trio_package': [0],\n",
    "            'cyo_package': [0],\n",
    "            'full_upgrade_package': [0],\n",
    "\n",
    "            # Seat features\n",
    "            'total_seats_sub': [0],\n",
    "\n",
    "            # Location features\n",
    "            'location_num_sub': [0],\n",
    "            # 'location_near_resident_num_sub': [-1],\n",
    "            # 'location_not_resident_num_sub': [-1],\n",
    "\n",
    "            # Section features\n",
    "            'section_type_numbers': [0],\n",
    "            'premium_orchestra_number': [0],\n",
    "            'orchestra_number': [0],\n",
    "            'balcony_number': [0],\n",
    "            'dress_circle_number': [0],\n",
    "            'Gallery_number': [0],\n",
    "            'Box_number': [0],\n",
    "            'floor_number': [0],\n",
    "\n",
    "            # Price features\n",
    "            'mean_price_level': [0],\n",
    "\n",
    "            'non_price_level_subscription': [0],\n",
    "\n",
    "            # Subscription tier features\n",
    "            'mean_subscription_tier': [0],\n",
    "            'multiple_subs_number': [0],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same player for their previous tickets\n",
    "            # 'has_previous_player': [has_previous_player],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same key_content for their previous tickets\n",
    "            # 'has_previous_key_content': [has_previous_key_content],\n",
    "            \n",
    "            # previous player and key_content subscription number\n",
    "            'previous_player_subscription_number': [0],\n",
    "\n",
    "            'previous_key_content_subscription_number': [0], \n",
    "\n",
    "            # other features\n",
    "            'account.id': [group['account.id'].iloc[0]],\n",
    "            \n",
    "            'label': [group['label'].iloc[0]] if 'label' in group.columns else [-1],\n",
    "            \n",
    "            'shipping.zip.code': [group['shipping.zip.code'].iloc[0]],\n",
    "            'billing.zip.code': [group['billing.zip.code'].iloc[0]],\n",
    "            'shipping_city': [shipping_city.iloc[0]],\n",
    "            'billing_city': [billing_city.iloc[0]],\n",
    "            'relationship': [group['relationship'].iloc[0]],\n",
    "            'amount.donated.2013': [group['amount.donated.2013'].iloc[0]],\n",
    "            'amount.donated.lifetime': [group['amount.donated.lifetime'].iloc[0]],\n",
    "            'no.donations.lifetime': [group['no.donations.lifetime'].iloc[0]],\n",
    "            'first.donated': [group['first.donated'].iloc[0]],\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24549\\AppData\\Local\\Temp\\ipykernel_30552\\569496751.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_merged = train_merged.groupby('account.id',group_keys=False).apply(handle_subscription)\n"
     ]
    }
   ],
   "source": [
    "# Merge train with account\n",
    "train_merged = pd.merge(train, account, on='account.id', how='left')\n",
    "\n",
    "# Merge train with subscriptions\n",
    "train_merged = pd.merge(train_merged, subscriptions, on='account.id', how='left')\n",
    "\n",
    "# Apply the function using groupby\n",
    "train_merged = train_merged.groupby('account.id',group_keys=False).apply(handle_subscription)\n",
    "\n",
    "train_merged=train_merged.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Tickets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' '1' '3' '2' nan '0' 'Adult' 'Youth' 'GA' '4.0']\n"
     ]
    }
   ],
   "source": [
    "tickets_all['multiple.tickets'].isna().sum()\n",
    "\n",
    "print(tickets_all['price.level'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tickets(group):\n",
    "    \n",
    "    other_columns = group.columns.difference([\n",
    "        'no.seats', 'price.level', 'location', 'set', 'multiple.tickets', 'season','marketing.source'\n",
    "    ])\n",
    "    if group['season'].notna().any():\n",
    "        \n",
    "        has_previous_player = False\n",
    "        has_previous_key_content = False\n",
    "\n",
    "        previous_player_ticket_number = 0\n",
    "        previous_key_content_ticket_number = 0\n",
    "    \n",
    "        for no_seats,season, location in zip(group['no.seats'],group['season'],group['location']):\n",
    "\n",
    "            result = concerts.query('season == @season and location == @location')\n",
    "\n",
    "            player_content = result['who']\n",
    "\n",
    "            key_content = result['what']\n",
    "            \n",
    "            # Join list items into a single regex pattern\n",
    "            pattern_player = \"|\".join(map(re.escape, player_1415))\n",
    "            pattern_content = \"|\".join(map(re.escape, key_content_1415))\n",
    "\n",
    "            # Check if any word is in the string\n",
    "            has_previous_player = player_content.str.contains(pattern_player,regex=True).any()\n",
    "            has_previous_key_content = key_content.str.contains(pattern_content,regex=True).any()\n",
    "\n",
    "            if has_previous_player :\n",
    "                previous_player_ticket_number += 1\n",
    "            \n",
    "            if has_previous_key_content:\n",
    "                previous_key_content_ticket_number += 1\n",
    "\n",
    "            \n",
    "\n",
    "        aggregated_data=pd.DataFrame({\n",
    "\n",
    "            # tickets sum\n",
    "            'sum_tickets': [group['no.seats'].sum()],\n",
    "\n",
    "            # price features\n",
    "            'average_price_level': [group['price.level'].mean()],\n",
    "            \n",
    "            # seats number features\n",
    "\n",
    "            'total_seats_ticket': [group['no.seats'].sum()],\n",
    "\n",
    "            # localtion features\n",
    "            'location_num_ticket': [group['location'].nunique()],\n",
    "            # 'location_near_resident_num_ticket': [(group['location'] == group['shipping_city']).sum() if group['shipping_city'].notna().any() else (group['location'] == group['billing_city']).sum()],\n",
    "            # 'location_not_resident_num_ticket': [group.shape[0] - (group['location'] == group['shipping_city']).sum() if group['shipping_city'].notna().any() else group.shape[0] - (group['location'] == group['billing_city']).sum()],\n",
    "            \n",
    "            # set features\n",
    "\n",
    "            'set sum': [group['set'].sum()],\n",
    "\n",
    "            # multiple_tickets features\n",
    "            'multiple_tickets_num': [(group['multiple.tickets'] == 'yes').sum()],\n",
    "            \n",
    "            # # Whether the 1415_concerts contain the same player for their previous tickets\n",
    "            # 'has_previous_player': [has_previous_player],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same key_content for their previous tickets\n",
    "            # 'has_previous_key_content': [has_previous_key_content],\n",
    "            \n",
    "            # previous player and key_content ticket number\n",
    "            'previous_player_ticket_number': [previous_player_ticket_number],\n",
    "\n",
    "            'previous_key_content_ticket_number': [previous_key_content_ticket_number], \n",
    "        })\n",
    "    \n",
    "    else:\n",
    "        aggregated_data=pd.DataFrame({\n",
    "            # tickets sum\n",
    "            'sum_tickets': [0],\n",
    "\n",
    "            # price features\n",
    "            'average_price_level': [0],\n",
    "            \n",
    "            # seats number features\n",
    "\n",
    "            'total_seats_ticket': [0],\n",
    "\n",
    "            # localtion features\n",
    "            'location_num_ticket': [0],\n",
    "            # 'location_near_resident_num_ticket': [-1],\n",
    "            # 'location_not_resident_num_ticket': [-1],\n",
    "            \n",
    "            # set features\n",
    "\n",
    "            'set sum': [0],\n",
    "\n",
    "            # multiple_tickets features\n",
    "            'multiple_tickets_num': [0],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same player for their previous tickets\n",
    "            # 'has_previous_player': [False],\n",
    "\n",
    "            # # Whether the 1415_concerts contain the same key_content for their previous tickets\n",
    "            # 'has_previous_key_content': [False],\n",
    "\n",
    "            # previous player and key_content ticket number\n",
    "            'previous_player_ticket_number': [0],\n",
    "\n",
    "            'previous_key_content_ticket_number': [0], \n",
    "\n",
    "        })\n",
    "\n",
    "    other_features = group.iloc[0][other_columns].to_frame().T.reset_index(drop=True)\n",
    "\n",
    "    # Set each column in `other_features` to its original data type\n",
    "    for col in other_columns:\n",
    "        other_features[col] = other_features[col].astype(group[col].dtype)\n",
    "\n",
    "\n",
    "    final_result = pd.concat([aggregated_data, other_features], axis=1)\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24549\\AppData\\Local\\Temp\\ipykernel_30552\\720989049.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_merged = train_merged.groupby('account.id',group_keys=False).apply(handle_tickets)\n"
     ]
    }
   ],
   "source": [
    "# to calculate the mean for the set column, first fillna with the mean of the value\n",
    "tickets_all['set']=tickets_all.groupby('account.id')['set'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "def handle_price_level(x):\n",
    "    if x in [\"Adult\", \"Youth\", \"GA\"]:\n",
    "        return float('nan')  # Set these values to NaN\n",
    "    return float(x)  # Convert other values to float\n",
    "\n",
    "# Apply the function to replace \"Adult\", \"Youth\", and \"GA\" with NaN, preparing for mean replacement\n",
    "tickets_all['price.level'] = tickets_all['price.level'].apply(handle_price_level)\n",
    "\n",
    "# Fill NaN values in 'price.level' with the group mean based on 'account.id'\n",
    "tickets_all['price.level'] = tickets_all.groupby('account.id')['price.level'].transform(lambda x: x.fillna(x.mean()) if x.notna().any() else x.fillna(-1))\n",
    "\n",
    "# merge train with tickets all\n",
    "\n",
    "train_merged = pd.merge(train_merged,tickets_all,on='account.id',how='left')\n",
    "\n",
    "train_merged = train_merged.groupby('account.id',group_keys=False).apply(handle_tickets)\n",
    "\n",
    "train_merged=train_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values,Duplicates and Outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: account.id, dtype: object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged[train_merged['mean_price_level'].isna()]['account.id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6941 entries, 0 to 6940\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   sum_tickets                               6941 non-null   float64\n",
      " 1   average_price_level                       6941 non-null   float64\n",
      " 2   total_seats_ticket                        6941 non-null   float64\n",
      " 3   location_num_ticket                       6941 non-null   int64  \n",
      " 4   set sum                                   6941 non-null   float64\n",
      " 5   multiple_tickets_num                      6941 non-null   int64  \n",
      " 6   previous_player_ticket_number             6941 non-null   int64  \n",
      " 7   previous_key_content_ticket_number        6941 non-null   int64  \n",
      " 8   Box_number                                6941 non-null   int64  \n",
      " 9   Gallery_number                            6941 non-null   int64  \n",
      " 10  account.id                                6941 non-null   object \n",
      " 11  amount.donated.2013                       6941 non-null   float64\n",
      " 12  amount.donated.lifetime                   6941 non-null   float64\n",
      " 13  balcony_number                            6941 non-null   int64  \n",
      " 14  billing.zip.code                          5961 non-null   object \n",
      " 15  billing_city                              6941 non-null   object \n",
      " 16  cyo_package                               6941 non-null   int64  \n",
      " 17  dress_circle_number                       6941 non-null   int64  \n",
      " 18  first.donated                             1934 non-null   object \n",
      " 19  floor_number                              6941 non-null   int64  \n",
      " 20  full_package                              6941 non-null   int64  \n",
      " 21  full_upgrade_package                      6941 non-null   int64  \n",
      " 22  label                                     6941 non-null   int64  \n",
      " 23  location_num_sub                          6941 non-null   int64  \n",
      " 24  mean_price_level                          6941 non-null   float64\n",
      " 25  mean_subscription_tier                    6941 non-null   float64\n",
      " 26  multiple_subs_number                      6941 non-null   int64  \n",
      " 27  no.donations.lifetime                     6941 non-null   int64  \n",
      " 28  non_price_level_subscription              6941 non-null   int64  \n",
      " 29  orchestra_number                          6941 non-null   int64  \n",
      " 30  premium_orchestra_number                  6941 non-null   int64  \n",
      " 31  previous_key_content_subscription_number  6941 non-null   int64  \n",
      " 32  previous_player_subscription_number       6941 non-null   int64  \n",
      " 33  quartet_package                           6941 non-null   int64  \n",
      " 34  relationship                              225 non-null    object \n",
      " 35  section_type_numbers                      6941 non-null   int64  \n",
      " 36  shipping.zip.code                         96 non-null     object \n",
      " 37  shipping_city                             6941 non-null   object \n",
      " 38  total_season                              6941 non-null   int64  \n",
      " 39  total_seats_sub                           6941 non-null   float64\n",
      " 40  trio_package                              6941 non-null   int64  \n",
      "dtypes: float64(9), int64(25), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Duplicate Rows\n",
    "train_merged=train_merged.drop_duplicates()\n",
    "\n",
    "# Delete shipping_city and billing_city because shipping_city is the same as shipping zip code and billing_city is the same as billing zip code\n",
    "\n",
    "train_merged=train_merged.drop(['shipping_city','billing_city'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_tickets                                    0\n",
       "average_price_level                            0\n",
       "total_seats_ticket                             0\n",
       "location_num_ticket                            0\n",
       "set sum                                        0\n",
       "multiple_tickets_num                           0\n",
       "previous_player_ticket_number                  0\n",
       "previous_key_content_ticket_number             0\n",
       "Box_number                                     0\n",
       "Gallery_number                                 0\n",
       "account.id                                     0\n",
       "amount.donated.2013                            0\n",
       "amount.donated.lifetime                        0\n",
       "balcony_number                                 0\n",
       "billing.zip.code                             980\n",
       "cyo_package                                    0\n",
       "dress_circle_number                            0\n",
       "first.donated                               5007\n",
       "floor_number                                   0\n",
       "full_package                                   0\n",
       "full_upgrade_package                           0\n",
       "label                                          0\n",
       "location_num_sub                               0\n",
       "mean_price_level                               0\n",
       "mean_subscription_tier                         0\n",
       "multiple_subs_number                           0\n",
       "no.donations.lifetime                          0\n",
       "non_price_level_subscription                   0\n",
       "orchestra_number                               0\n",
       "premium_orchestra_number                       0\n",
       "previous_key_content_subscription_number       0\n",
       "previous_player_subscription_number            0\n",
       "quartet_package                                0\n",
       "relationship                                6716\n",
       "section_type_numbers                           0\n",
       "shipping.zip.code                           6845\n",
       "total_season                                   0\n",
       "total_seats_sub                                0\n",
       "trio_package                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_tickets</th>\n",
       "      <th>average_price_level</th>\n",
       "      <th>total_seats_ticket</th>\n",
       "      <th>location_num_ticket</th>\n",
       "      <th>set sum</th>\n",
       "      <th>multiple_tickets_num</th>\n",
       "      <th>previous_player_ticket_number</th>\n",
       "      <th>previous_key_content_ticket_number</th>\n",
       "      <th>Box_number</th>\n",
       "      <th>Gallery_number</th>\n",
       "      <th>...</th>\n",
       "      <th>premium_orchestra_number</th>\n",
       "      <th>previous_key_content_subscription_number</th>\n",
       "      <th>previous_player_subscription_number</th>\n",
       "      <th>quartet_package</th>\n",
       "      <th>relationship</th>\n",
       "      <th>section_type_numbers</th>\n",
       "      <th>shipping.zip.code</th>\n",
       "      <th>total_season</th>\n",
       "      <th>total_seats_sub</th>\n",
       "      <th>trio_package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>94102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>21</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_tickets  average_price_level  total_seats_ticket  location_num_ticket  \\\n",
       "0          0.0                  0.0                 0.0                    0   \n",
       "1          0.0                  0.0                 0.0                    0   \n",
       "2          0.0                  0.0                 0.0                    0   \n",
       "3          0.0                  0.0                 0.0                    0   \n",
       "4          0.0                  0.0                 0.0                    0   \n",
       "\n",
       "   set sum  multiple_tickets_num  previous_player_ticket_number  \\\n",
       "0      0.0                     0                              0   \n",
       "1      0.0                     0                              0   \n",
       "2      0.0                     0                              0   \n",
       "3      0.0                     0                              0   \n",
       "4      0.0                     0                              0   \n",
       "\n",
       "   previous_key_content_ticket_number  Box_number  Gallery_number  ...  \\\n",
       "0                                   0           0               0  ...   \n",
       "1                                   0           0               0  ...   \n",
       "2                                   0           0               0  ...   \n",
       "3                                   0           0               0  ...   \n",
       "4                                   0           0               0  ...   \n",
       "\n",
       "  premium_orchestra_number  previous_key_content_subscription_number  \\\n",
       "0                        0                                         0   \n",
       "1                        4                                         4   \n",
       "2                        4                                         4   \n",
       "3                        2                                         3   \n",
       "4                        4                                         4   \n",
       "\n",
       "   previous_player_subscription_number  quartet_package relationship  \\\n",
       "0                                    0                0                \n",
       "1                                    4                0                \n",
       "2                                    4                0                \n",
       "3                                    3                3                \n",
       "4                                    4                0                \n",
       "\n",
       "   section_type_numbers  shipping.zip.code total_season  total_seats_sub  \\\n",
       "0                     0              94102            0              0.0   \n",
       "1                     3                              11             20.0   \n",
       "2                     3                              21             39.0   \n",
       "3                     3                              13             25.0   \n",
       "4                     4                              19             35.0   \n",
       "\n",
       "   trio_package  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA with empty string\n",
    "train_merged['shipping.zip.code']=train_merged['shipping.zip.code'].fillna(\"\")\n",
    "train_merged['billing.zip.code']=train_merged['billing.zip.code'].fillna(\"\")\n",
    "train_merged['relationship']=train_merged['relationship'].fillna(\"\")\n",
    "train_merged['first.donated']=train_merged.apply(lambda x: '1800-01-01 00:00:00' if x['no.donations.lifetime']==0 else (0 if pd.isna(x['first.donated']) else x['first.donated']),axis=1)\n",
    "\n",
    "train_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn first donated to timestamp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_tickets</th>\n",
       "      <th>average_price_level</th>\n",
       "      <th>total_seats_ticket</th>\n",
       "      <th>location_num_ticket</th>\n",
       "      <th>set sum</th>\n",
       "      <th>multiple_tickets_num</th>\n",
       "      <th>previous_player_ticket_number</th>\n",
       "      <th>previous_key_content_ticket_number</th>\n",
       "      <th>Box_number</th>\n",
       "      <th>Gallery_number</th>\n",
       "      <th>...</th>\n",
       "      <th>premium_orchestra_number</th>\n",
       "      <th>previous_key_content_subscription_number</th>\n",
       "      <th>previous_player_subscription_number</th>\n",
       "      <th>quartet_package</th>\n",
       "      <th>relationship</th>\n",
       "      <th>section_type_numbers</th>\n",
       "      <th>shipping.zip.code</th>\n",
       "      <th>total_season</th>\n",
       "      <th>total_seats_sub</th>\n",
       "      <th>trio_package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>94102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>21</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_tickets  average_price_level  total_seats_ticket  location_num_ticket  \\\n",
       "0          0.0                  0.0                 0.0                    0   \n",
       "1          0.0                  0.0                 0.0                    0   \n",
       "2          0.0                  0.0                 0.0                    0   \n",
       "3          0.0                  0.0                 0.0                    0   \n",
       "4          0.0                  0.0                 0.0                    0   \n",
       "\n",
       "   set sum  multiple_tickets_num  previous_player_ticket_number  \\\n",
       "0      0.0                     0                              0   \n",
       "1      0.0                     0                              0   \n",
       "2      0.0                     0                              0   \n",
       "3      0.0                     0                              0   \n",
       "4      0.0                     0                              0   \n",
       "\n",
       "   previous_key_content_ticket_number  Box_number  Gallery_number  ...  \\\n",
       "0                                   0           0               0  ...   \n",
       "1                                   0           0               0  ...   \n",
       "2                                   0           0               0  ...   \n",
       "3                                   0           0               0  ...   \n",
       "4                                   0           0               0  ...   \n",
       "\n",
       "  premium_orchestra_number  previous_key_content_subscription_number  \\\n",
       "0                        0                                         0   \n",
       "1                        4                                         4   \n",
       "2                        4                                         4   \n",
       "3                        2                                         3   \n",
       "4                        4                                         4   \n",
       "\n",
       "   previous_player_subscription_number  quartet_package relationship  \\\n",
       "0                                    0                0                \n",
       "1                                    4                0                \n",
       "2                                    4                0                \n",
       "3                                    3                3                \n",
       "4                                    4                0                \n",
       "\n",
       "   section_type_numbers  shipping.zip.code total_season  total_seats_sub  \\\n",
       "0                     0              94102            0              0.0   \n",
       "1                     3                              11             20.0   \n",
       "2                     3                              21             39.0   \n",
       "3                     3                              13             25.0   \n",
       "4                     4                              19             35.0   \n",
       "\n",
       "   trio_package  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged['first.donated'] = pd.to_datetime(train_merged['first.donated'])\n",
    "\n",
    "train_merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_tickets                                 0\n",
       "average_price_level                         0\n",
       "total_seats_ticket                          0\n",
       "location_num_ticket                         0\n",
       "set sum                                     0\n",
       "multiple_tickets_num                        0\n",
       "previous_player_ticket_number               0\n",
       "previous_key_content_ticket_number          0\n",
       "Box_number                                  0\n",
       "Gallery_number                              0\n",
       "account.id                                  0\n",
       "amount.donated.2013                         0\n",
       "amount.donated.lifetime                     0\n",
       "balcony_number                              0\n",
       "billing.zip.code                            0\n",
       "cyo_package                                 0\n",
       "dress_circle_number                         0\n",
       "first.donated                               0\n",
       "floor_number                                0\n",
       "full_package                                0\n",
       "full_upgrade_package                        0\n",
       "label                                       0\n",
       "location_num_sub                            0\n",
       "mean_price_level                            0\n",
       "mean_subscription_tier                      0\n",
       "multiple_subs_number                        0\n",
       "no.donations.lifetime                       0\n",
       "non_price_level_subscription                0\n",
       "orchestra_number                            0\n",
       "premium_orchestra_number                    0\n",
       "previous_key_content_subscription_number    0\n",
       "previous_player_subscription_number         0\n",
       "quartet_package                             0\n",
       "relationship                                0\n",
       "section_type_numbers                        0\n",
       "shipping.zip.code                           0\n",
       "total_season                                0\n",
       "total_seats_sub                             0\n",
       "trio_package                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "train_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## WOE Encoding\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "# Use WoE to encode shipping zip code and billing zip code\n",
    "\n",
    "woe = ce.WOEEncoder([ 'shipping.zip.code', 'billing.zip.code','relationship'])\n",
    "\n",
    "train_merged['shipping.zip.code'] = train_merged['shipping.zip.code'].astype(str)\n",
    "train_merged['billing.zip.code'] = train_merged['billing.zip.code'].astype(str)\n",
    "\n",
    "woe.fit(train_merged[['shipping.zip.code', 'billing.zip.code','relationship']], train_merged['label'])\n",
    "\n",
    "train_merged[['shipping.zip.code', 'billing.zip.code','relationship']] = woe.transform(train_merged[['shipping.zip.code', 'billing.zip.code','relationship']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sum_tickets', 'average_price_level', 'total_seats_ticket',\n",
       "       'location_num_ticket', 'set sum', 'multiple_tickets_num',\n",
       "       'previous_player_ticket_number', 'previous_key_content_ticket_number',\n",
       "       'Box_number', 'Gallery_number', 'account.id', 'amount.donated.2013',\n",
       "       'amount.donated.lifetime', 'balcony_number', 'billing.zip.code',\n",
       "       'cyo_package', 'dress_circle_number', 'floor_number', 'full_package',\n",
       "       'full_upgrade_package', 'label', 'location_num_sub', 'mean_price_level',\n",
       "       'mean_subscription_tier', 'multiple_subs_number',\n",
       "       'no.donations.lifetime', 'non_price_level_subscription',\n",
       "       'orchestra_number', 'premium_orchestra_number',\n",
       "       'previous_key_content_subscription_number',\n",
       "       'previous_player_subscription_number', 'quartet_package',\n",
       "       'relationship', 'section_type_numbers', 'shipping.zip.code',\n",
       "       'total_season', 'total_seats_sub', 'trio_package',\n",
       "       'days_since_first_donation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of days since the first donation\n",
    "\n",
    "now = pd.to_datetime('2014-09-01')\n",
    "\n",
    "train_merged['days_since_first_donation'] = (now - train_merged['first.donated']).dt.days\n",
    "\n",
    "# drop first donated column\n",
    "\n",
    "train_merged=train_merged.drop(['first.donated'],axis=1)\n",
    "\n",
    "train_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check TrainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6941 entries, 0 to 6940\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   sum_tickets                               6941 non-null   float64\n",
      " 1   average_price_level                       6941 non-null   float64\n",
      " 2   total_seats_ticket                        6941 non-null   float64\n",
      " 3   location_num_ticket                       6941 non-null   int64  \n",
      " 4   set sum                                   6941 non-null   float64\n",
      " 5   multiple_tickets_num                      6941 non-null   int64  \n",
      " 6   previous_player_ticket_number             6941 non-null   int64  \n",
      " 7   previous_key_content_ticket_number        6941 non-null   int64  \n",
      " 8   Box_number                                6941 non-null   int64  \n",
      " 9   Gallery_number                            6941 non-null   int64  \n",
      " 10  account.id                                6941 non-null   object \n",
      " 11  amount.donated.2013                       6941 non-null   float64\n",
      " 12  amount.donated.lifetime                   6941 non-null   float64\n",
      " 13  balcony_number                            6941 non-null   int64  \n",
      " 14  billing.zip.code                          6941 non-null   float64\n",
      " 15  cyo_package                               6941 non-null   int64  \n",
      " 16  dress_circle_number                       6941 non-null   int64  \n",
      " 17  floor_number                              6941 non-null   int64  \n",
      " 18  full_package                              6941 non-null   int64  \n",
      " 19  full_upgrade_package                      6941 non-null   int64  \n",
      " 20  label                                     6941 non-null   int64  \n",
      " 21  location_num_sub                          6941 non-null   int64  \n",
      " 22  mean_price_level                          6941 non-null   float64\n",
      " 23  mean_subscription_tier                    6941 non-null   float64\n",
      " 24  multiple_subs_number                      6941 non-null   int64  \n",
      " 25  no.donations.lifetime                     6941 non-null   int64  \n",
      " 26  non_price_level_subscription              6941 non-null   int64  \n",
      " 27  orchestra_number                          6941 non-null   int64  \n",
      " 28  premium_orchestra_number                  6941 non-null   int64  \n",
      " 29  previous_key_content_subscription_number  6941 non-null   int64  \n",
      " 30  previous_player_subscription_number       6941 non-null   int64  \n",
      " 31  quartet_package                           6941 non-null   int64  \n",
      " 32  relationship                              6941 non-null   float64\n",
      " 33  section_type_numbers                      6941 non-null   int64  \n",
      " 34  shipping.zip.code                         6941 non-null   float64\n",
      " 35  total_season                              6941 non-null   int64  \n",
      " 36  total_seats_sub                           6941 non-null   float64\n",
      " 37  trio_package                              6941 non-null   int64  \n",
      " 38  days_since_first_donation                 6941 non-null   int64  \n",
      "dtypes: float64(12), int64(26), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_merged['has_previous_key_content'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name\n",
    "\n",
    "test['account.id']=test['ID']\n",
    "test.drop(['ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24549\\AppData\\Local\\Temp\\ipykernel_30552\\1953010395.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_merged = test_merged.groupby('account.id',group_keys=False).apply(handle_subscription)\n"
     ]
    }
   ],
   "source": [
    "# Merge test with account\n",
    "test_merged = pd.merge(test, account, on='account.id', how='left')\n",
    "\n",
    "# Merge test with subscriptions\n",
    "test_merged = pd.merge(test_merged, subscriptions, on='account.id', how='left')\n",
    "\n",
    "# Apply the function using groupby\n",
    "test_merged = test_merged.groupby('account.id',group_keys=False).apply(handle_subscription)\n",
    "\n",
    "test_merged=test_merged.reset_index(drop=True)\n",
    "\n",
    "test_merged.drop(['label'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24549\\AppData\\Local\\Temp\\ipykernel_30552\\2232742302.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_merged = test_merged.groupby('account.id',group_keys=False).apply(handle_tickets)\n"
     ]
    }
   ],
   "source": [
    "# merge test with tickets all\n",
    "\n",
    "test_merged = pd.merge(test_merged,tickets_all,on='account.id',how='left')\n",
    "\n",
    "test_merged = test_merged.groupby('account.id',group_keys=False).apply(handle_tickets)\n",
    "\n",
    "test_merged=test_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Duplicate Rows\n",
    "test_merged=test_merged.drop_duplicates()\n",
    "\n",
    "# Delete shipping_city and billing_city because shipping_city is the same as shipping zip code and billing_city is the same as billing zip code\n",
    "\n",
    "test_merged=test_merged.drop(['shipping_city','billing_city'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with empty string\n",
    "test_merged['shipping.zip.code']=test_merged['shipping.zip.code'].fillna(\"\")\n",
    "test_merged['billing.zip.code']=test_merged['billing.zip.code'].fillna(\"\")\n",
    "test_merged['relationship']=test_merged['relationship'].fillna(\"\")\n",
    "test_merged['first.donated']=test_merged.apply(lambda x: '1800-01-01 00:00:00' if x['no.donations.lifetime']==0 else (0 if pd.isna(x['first.donated']) else x['first.donated']),axis=1)\n",
    "\n",
    "# change to the type of datetime\n",
    "test_merged['first.donated'] = pd.to_datetime(test_merged['first.donated'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "test_merged[['shipping.zip.code', 'billing.zip.code','relationship']] = woe.transform(test_merged[['shipping.zip.code', 'billing.zip.code','relationship']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_tickets</th>\n",
       "      <th>average_price_level</th>\n",
       "      <th>total_seats_ticket</th>\n",
       "      <th>location_num_ticket</th>\n",
       "      <th>set sum</th>\n",
       "      <th>multiple_tickets_num</th>\n",
       "      <th>previous_player_ticket_number</th>\n",
       "      <th>previous_key_content_ticket_number</th>\n",
       "      <th>Box_number</th>\n",
       "      <th>Gallery_number</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_key_content_subscription_number</th>\n",
       "      <th>previous_player_subscription_number</th>\n",
       "      <th>quartet_package</th>\n",
       "      <th>relationship</th>\n",
       "      <th>section_type_numbers</th>\n",
       "      <th>shipping.zip.code</th>\n",
       "      <th>total_season</th>\n",
       "      <th>total_seats_sub</th>\n",
       "      <th>trio_package</th>\n",
       "      <th>days_since_first_donation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>19</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>21</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_tickets  average_price_level  total_seats_ticket  location_num_ticket  \\\n",
       "0          0.0                  0.0                 0.0                    0   \n",
       "1          0.0                  0.0                 0.0                    0   \n",
       "2          0.0                  0.0                 0.0                    0   \n",
       "3          0.0                  0.0                 0.0                    0   \n",
       "4          0.0                  0.0                 0.0                    0   \n",
       "\n",
       "   set sum  multiple_tickets_num  previous_player_ticket_number  \\\n",
       "0      0.0                     0                              0   \n",
       "1      0.0                     0                              0   \n",
       "2      0.0                     0                              0   \n",
       "3      0.0                     0                              0   \n",
       "4      0.0                     0                              0   \n",
       "\n",
       "   previous_key_content_ticket_number  Box_number  Gallery_number  ...  \\\n",
       "0                                   0           0               0  ...   \n",
       "1                                   0           0               0  ...   \n",
       "2                                   0           0               0  ...   \n",
       "3                                   0           0               0  ...   \n",
       "4                                   0           0               0  ...   \n",
       "\n",
       "  previous_key_content_subscription_number  \\\n",
       "0                                        4   \n",
       "1                                        4   \n",
       "2                                        4   \n",
       "3                                        4   \n",
       "4                                        4   \n",
       "\n",
       "   previous_player_subscription_number  quartet_package  relationship  \\\n",
       "0                                    4                0      0.031785   \n",
       "1                                    4                0      0.031785   \n",
       "2                                    4                0      0.031785   \n",
       "3                                    4                3      0.031785   \n",
       "4                                    4                4      0.031785   \n",
       "\n",
       "   section_type_numbers  shipping.zip.code  total_season  total_seats_sub  \\\n",
       "0                     3          -0.013762            19             35.0   \n",
       "1                     3          -0.013762            16             30.0   \n",
       "2                     4          -0.013762            16             29.0   \n",
       "3                     2          -0.013762             7             14.0   \n",
       "4                     4          -0.013762            21             39.0   \n",
       "\n",
       "   trio_package  days_since_first_donation  \n",
       "0             0                      10286  \n",
       "1             1                       6356  \n",
       "2             0                       5752  \n",
       "3             4                       2668  \n",
       "4             0                       9555  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of days since the first donation\n",
    "\n",
    "now = pd.to_datetime('2014-09-01')\n",
    "\n",
    "test_merged['days_since_first_donation'] = (now - test_merged['first.donated']).dt.days\n",
    "\n",
    "# drop first donated column\n",
    "\n",
    "test_merged=test_merged.drop(['first.donated'],axis=1)\n",
    "\n",
    "test_merged.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    001i000000LhyPF\n",
       "1    001i000000LhyPG\n",
       "2    001i000000LhyPP\n",
       "3    001i000000LhyPb\n",
       "4    001i000000LhyPg\n",
       "Name: account.id, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged['account.id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "\n",
    "X_train=train_merged.drop(['label','account.id'],axis=1)\n",
    "y_train=train_merged['label']\n",
    "\n",
    "X_test=test_merged.drop(['account.id'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.drop(['shipping.zip.code','billing.zip.code'],axis=1,inplace=True)\n",
    "# X_test.drop(['shipping.zip.code','billing.zip.code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "\n",
    "# Scale train data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "train_scaled=X_train.copy()\n",
    "\n",
    "scaler.fit(train_scaled[numerical_cols])\n",
    "\n",
    "train_scaled[numerical_cols] = scaler.transform(train_scaled[numerical_cols])\n",
    "\n",
    "# Scale test data\n",
    "\n",
    "test_scaled=X_test.copy()\n",
    "\n",
    "test_scaled[numerical_cols] = scaler.transform(test_scaled[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training And Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor as cat\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron\n",
    "\n",
    "# Split data\n",
    "X_train_torch, X_val_torch, y_train_torch, y_val_torch = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the dataset\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)  # Convert X to float32 tensor\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32) if y is not None else None  # Convert y to float32 tensor if available\\\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]\n",
    "    \n",
    "train_dataset = TabularDataset(X_train_torch, y_train_torch)\n",
    "\n",
    "val_dataset = TabularDataset(X_val_torch, y_val_torch)\n",
    "\n",
    "# Define the Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_train_torch.shape[1]\n",
    "model = MLP(input_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=2000):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch).squeeze()\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.tolist())\n",
    "                val_targets.extend(y_batch.tolist())\n",
    "        \n",
    "        # Calculate AUROC for validation set\n",
    "        val_auroc = roc_auc_score(val_targets, val_preds)\n",
    "        if epoch%10==0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "                f\"Val Loss: {val_loss/len(val_loader):.4f}, Val AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "def mlp():\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_dataset = TabularDataset(X_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            test_preds.extend(outputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold cross validation\n",
    "\n",
    "splits = 5\n",
    "\n",
    "kf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "def cv_model(clf, x_train, y_train, x_test, clf_name , kf):\n",
    "    \n",
    "    cv_scores = []\n",
    "\n",
    "    test_all = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(x_train, y_train)):\n",
    "\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "\n",
    "        trn_x, trn_y, val_x, val_y = x_train.iloc[train_index], y_train[train_index], x_train.iloc[valid_index], y_train[valid_index]\n",
    "\n",
    "        # LightGBM\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            # training parameters\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 4,\n",
    "                'num_leaves': 2 ** 4,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.7,\n",
    "                'bagging_fraction': 0.7,\n",
    "                'bagging_freq': 10,\n",
    "                'learning_rate': 0.15,\n",
    "                'seed': 2022,\n",
    "                'n_jobs':-1,\n",
    "                'verbose':-1\n",
    "            }\n",
    "            # model training\n",
    "            model = clf.train(params, train_matrix, 30000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[])\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "        \n",
    "        # XGBoost\n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(x_test)\n",
    "            \n",
    "            # training parameters\n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 7,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.125,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "\n",
    "            # model training\n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist,verbose_eval=True)\n",
    "            val_pred  = model.predict(valid_matrix)\n",
    "            test_pred = model.predict(test_matrix)\n",
    "\n",
    "        # Catboost         \n",
    "        if clf_name == \"cat\":\n",
    "            \n",
    "            # training parameters\n",
    "            params = {'learning_rate': 0.134, \n",
    "            'depth': 10 ,\n",
    "            'l2_leaf_reg': 5, \n",
    "            'bootstrap_type': 'Bernoulli',\n",
    "            'od_type': 'Iter', \n",
    "            'od_wait': 2000, \n",
    "            'random_seed': 164, \n",
    "            'allow_writing_files': False\n",
    "            }\n",
    "\n",
    "            # model training\n",
    "            model = clf(iterations=30000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=600)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(x_test)\n",
    "        \n",
    "\n",
    "        test_all.append(test_pred)\n",
    "\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "\n",
    "    # output\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "\n",
    "    # Convert test_all (list of lists) to a NumPy array\n",
    "    test_all_array = np.array(test_all)\n",
    "\n",
    "    # Calculate the mean across the lists (axis=0 computes mean element-wise across all lists)\n",
    "    mean_output = np.mean(test_all_array, axis=0)\n",
    "\n",
    "    return mean_output\n",
    "        \n",
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\", kf)\n",
    "    return lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\", kf)\n",
    "    return xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_test = cv_model(cat, x_train, y_train, x_test, \"cat\", kf)\n",
    "    return cat_test\n",
    "\n",
    "def mlp_model(x_train, y_train, x_test):\n",
    "    mlp_test = mlp()\n",
    "    return mlp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_tickets</th>\n",
       "      <th>average_price_level</th>\n",
       "      <th>total_seats_ticket</th>\n",
       "      <th>location_num_ticket</th>\n",
       "      <th>set sum</th>\n",
       "      <th>multiple_tickets_num</th>\n",
       "      <th>previous_player_ticket_number</th>\n",
       "      <th>previous_key_content_ticket_number</th>\n",
       "      <th>Box_number</th>\n",
       "      <th>Gallery_number</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_key_content_subscription_number</th>\n",
       "      <th>previous_player_subscription_number</th>\n",
       "      <th>quartet_package</th>\n",
       "      <th>relationship</th>\n",
       "      <th>section_type_numbers</th>\n",
       "      <th>shipping.zip.code</th>\n",
       "      <th>total_season</th>\n",
       "      <th>total_seats_sub</th>\n",
       "      <th>trio_package</th>\n",
       "      <th>days_since_first_donation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>19</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>16</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>21</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_tickets  average_price_level  total_seats_ticket  location_num_ticket  \\\n",
       "0          0.0                  0.0                 0.0                    0   \n",
       "1          0.0                  0.0                 0.0                    0   \n",
       "2          0.0                  0.0                 0.0                    0   \n",
       "3          0.0                  0.0                 0.0                    0   \n",
       "4          0.0                  0.0                 0.0                    0   \n",
       "\n",
       "   set sum  multiple_tickets_num  previous_player_ticket_number  \\\n",
       "0      0.0                     0                              0   \n",
       "1      0.0                     0                              0   \n",
       "2      0.0                     0                              0   \n",
       "3      0.0                     0                              0   \n",
       "4      0.0                     0                              0   \n",
       "\n",
       "   previous_key_content_ticket_number  Box_number  Gallery_number  ...  \\\n",
       "0                                   0           0               0  ...   \n",
       "1                                   0           0               0  ...   \n",
       "2                                   0           0               0  ...   \n",
       "3                                   0           0               0  ...   \n",
       "4                                   0           0               0  ...   \n",
       "\n",
       "   previous_key_content_subscription_number  \\\n",
       "0                                         4   \n",
       "1                                         4   \n",
       "2                                         4   \n",
       "3                                         4   \n",
       "4                                         4   \n",
       "\n",
       "   previous_player_subscription_number  quartet_package  relationship  \\\n",
       "0                                    4                0      0.031785   \n",
       "1                                    4                0      0.031785   \n",
       "2                                    4                0      0.031785   \n",
       "3                                    4                3      0.031785   \n",
       "4                                    4                4      0.031785   \n",
       "\n",
       "   section_type_numbers  shipping.zip.code  total_season  total_seats_sub  \\\n",
       "0                     3          -0.013762            19             35.0   \n",
       "1                     3          -0.013762            16             30.0   \n",
       "2                     4          -0.013762            16             29.0   \n",
       "3                     2          -0.013762             7             14.0   \n",
       "4                     4          -0.013762            21             39.0   \n",
       "\n",
       "   trio_package  days_since_first_donation  \n",
       "0             0                      10286  \n",
       "1             1                       6356  \n",
       "2             0                       5752  \n",
       "3             4                       2668  \n",
       "4             0                       9555  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_test=lgb_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_test=xgb_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "0:\tlearn: 0.1905256\ttest: 0.2206669\tbest: 0.2206669 (0)\ttotal: 9.04ms\tremaining: 4m 31s\n",
      "600:\tlearn: 0.0364386\ttest: 0.1263373\tbest: 0.1239914 (249)\ttotal: 4.74s\tremaining: 3m 51s\n",
      "1200:\tlearn: 0.0327356\ttest: 0.1274662\tbest: 0.1239914 (249)\ttotal: 9.47s\tremaining: 3m 47s\n",
      "1800:\tlearn: 0.0322458\ttest: 0.1276707\tbest: 0.1239914 (249)\ttotal: 14.1s\tremaining: 3m 40s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.1239914055\n",
      "bestIteration = 249\n",
      "\n",
      "Shrink model to first 250 iterations.\n",
      "[0.9619275679620509]\n",
      "************************************ 2 ************************************\n",
      "0:\tlearn: 0.1964664\ttest: 0.1959328\tbest: 0.1959328 (0)\ttotal: 8.53ms\tremaining: 4m 15s\n",
      "600:\tlearn: 0.0441843\ttest: 0.1285691\tbest: 0.1209724 (79)\ttotal: 4.78s\tremaining: 3m 53s\n",
      "1200:\tlearn: 0.0419066\ttest: 0.1298813\tbest: 0.1209724 (79)\ttotal: 9.68s\tremaining: 3m 52s\n",
      "1800:\tlearn: 0.0416596\ttest: 0.1301831\tbest: 0.1209724 (79)\ttotal: 14.5s\tremaining: 3m 47s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.1209724053\n",
      "bestIteration = 79\n",
      "\n",
      "Shrink model to first 80 iterations.\n",
      "[0.9619275679620509, 0.9685967083849081]\n",
      "************************************ 3 ************************************\n",
      "0:\tlearn: 0.2003526\ttest: 0.1922986\tbest: 0.1922986 (0)\ttotal: 4.9ms\tremaining: 2m 26s\n",
      "600:\tlearn: 0.0412514\ttest: 0.1216081\tbest: 0.1140646 (36)\ttotal: 4.69s\tremaining: 3m 49s\n",
      "1200:\tlearn: 0.0373557\ttest: 0.1233161\tbest: 0.1140646 (36)\ttotal: 9.42s\tremaining: 3m 45s\n",
      "1800:\tlearn: 0.0367692\ttest: 0.1237995\tbest: 0.1140646 (36)\ttotal: 14.1s\tremaining: 3m 40s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.1140646404\n",
      "bestIteration = 36\n",
      "\n",
      "Shrink model to first 37 iterations.\n",
      "[0.9619275679620509, 0.9685967083849081, 0.9692745584586192]\n",
      "************************************ 4 ************************************\n",
      "0:\tlearn: 0.1996526\ttest: 0.1937952\tbest: 0.1937952 (0)\ttotal: 8.76ms\tremaining: 4m 22s\n",
      "600:\tlearn: 0.0411161\ttest: 0.1288940\tbest: 0.1182222 (31)\ttotal: 4.61s\tremaining: 3m 45s\n",
      "1200:\tlearn: 0.0366438\ttest: 0.1318890\tbest: 0.1182222 (31)\ttotal: 9.32s\tremaining: 3m 43s\n",
      "1800:\tlearn: 0.0361299\ttest: 0.1322689\tbest: 0.1182222 (31)\ttotal: 14.1s\tremaining: 3m 40s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.118222198\n",
      "bestIteration = 31\n",
      "\n",
      "Shrink model to first 32 iterations.\n",
      "[0.9619275679620509, 0.9685967083849081, 0.9692745584586192, 0.9749975672651194]\n",
      "************************************ 5 ************************************\n",
      "0:\tlearn: 0.2002383\ttest: 0.1870731\tbest: 0.1870731 (0)\ttotal: 9.04ms\tremaining: 4m 31s\n",
      "600:\tlearn: 0.0468167\ttest: 0.1178069\tbest: 0.1163384 (175)\ttotal: 4.67s\tremaining: 3m 48s\n",
      "1200:\tlearn: 0.0434095\ttest: 0.1182705\tbest: 0.1163384 (175)\ttotal: 9.41s\tremaining: 3m 45s\n",
      "1800:\tlearn: 0.0428313\ttest: 0.1184187\tbest: 0.1163384 (175)\ttotal: 14.1s\tremaining: 3m 41s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.1163383642\n",
      "bestIteration = 175\n",
      "\n",
      "Shrink model to first 176 iterations.\n",
      "[0.9619275679620509, 0.9685967083849081, 0.9692745584586192, 0.9749975672651194, 0.9925330567798807]\n",
      "cat_scotrainre_list: [0.9619275679620509, 0.9685967083849081, 0.9692745584586192, 0.9749975672651194, 0.9925330567798807]\n",
      "cat_score_mean: 0.9734658917701158\n",
      "cat_score_std: 0.010395306146508602\n"
     ]
    }
   ],
   "source": [
    "cat_test=cat_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_test=mlp_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Data to Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the results to the test merged\n",
    "\n",
    "# I choose catboost for the final model\n",
    "\n",
    "output=pd.DataFrame({'ID':test_merged['account.id'],'Predicted':cat_test})\n",
    "\n",
    "output.to_csv('submission.csv',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
